{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to pythorvision","text":"<p>This is the documentation for <code>pythorvision</code>, a Python client for the XDAQ camera streaming server.</p>"},{"location":"camera/","title":"Camera API Reference","text":""},{"location":"camera/#pythorvision.camera","title":"pythorvision.camera","text":""},{"location":"camera/#pythorvision.camera.Camera","title":"Camera","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a camera device.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>int</code> <p>The unique identifier for the camera.</p> <code>name</code> <code>str</code> <p>The name of the camera.</p> <code>capabilities</code> <code>List[Capability]</code> <p>A list of supported capabilities for the camera.</p>"},{"location":"camera/#pythorvision.camera.Capability","title":"Capability","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a single capability of a camera.</p> <p>Attributes:</p> Name Type Description <code>media_type</code> <code>str</code> <p>The media type of the capability (e.g., 'image/jpeg').</p> <code>format</code> <code>Optional[str]</code> <p>The format of the media (e.g., 'NV12').</p> <code>width</code> <code>int</code> <p>The width of the video frame.</p> <code>height</code> <code>int</code> <p>The height of the video frame.</p> <code>framerate</code> <code>str</code> <p>The framerate as a fraction (e.g., '30/1').</p>"},{"location":"camera/#pythorvision.camera.Capability.to_gstreamer_capability","title":"to_gstreamer_capability","text":"<pre><code>to_gstreamer_capability()\n</code></pre> <p>Convert the capability to a GStreamer capability string.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The GStreamer capability string.</p> Source code in <code>pythorvision/camera.py</code> <pre><code>def to_gstreamer_capability(self) -&gt; str:\n    \"\"\"Convert the capability to a GStreamer capability string.\n\n    Returns:\n        str: The GStreamer capability string.\n    \"\"\"\n    if self.format:\n        return f\"{self.media_type},format={self.format},width={self.width},height={self.height},framerate={self.framerate}\"\n    return f\"{self.media_type},width={self.width},height={self.height},framerate={self.framerate}\"\n</code></pre>"},{"location":"client/","title":"Client API Reference","text":""},{"location":"client/#pythorvision.client","title":"pythorvision.client","text":""},{"location":"client/#pythorvision.client.Stream","title":"Stream","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents an active video stream and its associated resources.</p> <p>Attributes:</p> Name Type Description <code>camera</code> <code>Camera</code> <p>The camera being streamed.</p> <code>capability</code> <code>Capability</code> <p>The capability used for the stream.</p> <code>port</code> <code>int</code> <p>The network port used for the SRT stream.</p> <code>video_path</code> <code>Path</code> <p>The path to the recorded video file.</p> <code>gstreamer_pipeline</code> <code>str</code> <p>The GStreamer pipeline command used.</p> <code>process</code> <code>Popen</code> <p>The Popen object for the running GStreamer process.</p> <code>gstreamer_log_file</code> <code>Optional[TextIOBase]</code> <p>The file handle for GStreamer logs.</p> <code>gstreamer_log_file_path</code> <code>Optional[Path]</code> <p>The path to the GStreamer log file.</p> <code>created_at</code> <code>datetime</code> <p>The timestamp when the stream was created.</p>"},{"location":"client/#pythorvision.client.ThorVisionClient","title":"ThorVisionClient","text":"<p>               Bases: <code>BaseModel</code></p> <p>Client for interacting with the ThorVision server to manage camera streams.</p> <p>Attributes:</p> Name Type Description <code>host</code> <code>str</code> <p>The hostname or IP address of the ThorVision server.</p> <code>port</code> <code>int</code> <p>The port number of the ThorVision server.</p> <code>streams</code> <code>Dict[int, Stream]</code> <p>A dictionary of active streams, keyed by camera ID.</p>"},{"location":"client/#pythorvision.client.ThorVisionClient.__del__","title":"__del__","text":"<pre><code>__del__()\n</code></pre> <p>Ensure all streams are cleaned up when the client is destroyed.</p> Source code in <code>pythorvision/client.py</code> <pre><code>def __del__(self):\n    \"\"\"Ensure all streams are cleaned up when the client is destroyed.\"\"\"\n    self.clean_streams()\n</code></pre>"},{"location":"client/#pythorvision.client.ThorVisionClient.clean_streams","title":"clean_streams","text":"<pre><code>clean_streams()\n</code></pre> <p>Stop all active streams and clean up all resources.</p> <p>This is useful for gracefully shutting down the client.</p> Source code in <code>pythorvision/client.py</code> <pre><code>def clean_streams(self):\n    \"\"\"Stop all active streams and clean up all resources.\n\n    This is useful for gracefully shutting down the client.\n    \"\"\"\n    logger.info(\"Starting cleanup of all streams\")\n    camera_ids = list(self.streams.keys())\n\n    for camera_id in camera_ids:\n        try:\n            self.stop_stream(camera_id)\n        except Exception as e:\n            logger.error(f\"Error stopping stream for camera {camera_id}: {e}\")\n\n    logger.info(\"All resources cleaned up\")\n</code></pre>"},{"location":"client/#pythorvision.client.ThorVisionClient.get_logs","title":"get_logs","text":"<pre><code>get_logs(file_name=None)\n</code></pre> <p>Fetch the logs from ThorVision server.</p> <p>Parameters:</p> Name Type Description Default <code>file_name</code> <code>Optional[str]</code> <p>The name of the file to get logs for.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The logs for the file.</p> Source code in <code>pythorvision/client.py</code> <pre><code>def get_logs(self, file_name: Optional[str] = None) -&gt; str:\n    \"\"\"Fetch the logs from ThorVision server.\n\n    Args:\n        file_name (Optional[str]): The name of the file to get logs for.\n\n    Returns:\n        str: The logs for the file.\n    \"\"\"\n    endpoint = f\"{self._base_url}/logs\"\n    if file_name:\n        endpoint += f\"/{file_name}\"\n\n    try:\n        logger.info(f\"Fetching logs from {endpoint}\")\n        response = requests.get(endpoint, timeout=5)\n        response.raise_for_status()\n        return response.text\n    except requests.exceptions.Timeout:\n        raise RuntimeError(\"Request timed out fetching logs.\")\n    except requests.exceptions.HTTPError:\n        raise RuntimeError(f\"Server returned error {response.status_code}: {response.text}\")\n    except requests.exceptions.RequestException as e:\n        raise RuntimeError(f\"Failed to fetch logs: {str(e)}\") from e\n</code></pre>"},{"location":"client/#pythorvision.client.ThorVisionClient.list_cameras","title":"list_cameras","text":"<pre><code>list_cameras()\n</code></pre> <p>Retrieve a list of available cameras from the ThorVision server.</p> <p>Returns:</p> Type Description <code>List[Camera]</code> <p>List[Camera]: A list of Camera objects.</p> <p>Raises:</p> Type Description <code>RequestException</code> <p>If there is an issue communicating with the server.</p> Source code in <code>pythorvision/client.py</code> <pre><code>def list_cameras(self) -&gt; List[Camera]:\n    \"\"\"Retrieve a list of available cameras from the ThorVision server.\n\n    Returns:\n        List[Camera]: A list of Camera objects.\n\n    Raises:\n        requests.exceptions.RequestException: If there is an issue\n            communicating with the server.\n    \"\"\"\n    response = requests.get(f\"{self._base_url}/cameras\", timeout=5)\n    response.raise_for_status()\n    cameras_data = response.json()\n    return [Camera(**cam_data) for cam_data in cameras_data]\n</code></pre>"},{"location":"client/#pythorvision.client.ThorVisionClient.model_post_init","title":"model_post_init","text":"<pre><code>model_post_init(__context)\n</code></pre> <p>Initialize the client after the model is created.</p> <p>This method sets up the base URL for the server and performs initial checks for server connectivity and GStreamer installation.</p> <p>Parameters:</p> Name Type Description Default <code>__context</code> <code>Any</code> <p>The context for model initialization.</p> required Source code in <code>pythorvision/client.py</code> <pre><code>def model_post_init(self, __context: Any) -&gt; None:\n    \"\"\"Initialize the client after the model is created.\n\n    This method sets up the base URL for the server and performs initial\n    checks for server connectivity and GStreamer installation.\n\n    Args:\n        __context (Any): The context for model initialization.\n    \"\"\"\n    self._base_url = f\"http://{self.host}:{self.port}\"\n    logger.info(f\"Initializing ThorVisionClient for {self._base_url}\")\n    self._check_host()\n    self._check_gstreamer()\n</code></pre>"},{"location":"client/#pythorvision.client.ThorVisionClient.start_stream_with_recording","title":"start_stream_with_recording","text":"<pre><code>start_stream_with_recording(camera, capability, output_dir, split_max_files=0, split_max_time_sec=0, split_max_size_mb=0, gstreamer_debug=False)\n</code></pre> <p>Start a camera stream and record it to a file.</p> <p>This method requests the server to start streaming a camera's feed, then launches a local GStreamer process to receive and record the stream. The recording can be split into multiple files based on time, size, or number of files.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>Camera</code> <p>The camera to start streaming.</p> required <code>capability</code> <code>Capability</code> <p>The desired stream capability (resolution, format, etc.).</p> required <code>output_dir</code> <code>str</code> <p>The directory to save the recording files.</p> required <code>split_max_files</code> <code>Optional[int]</code> <p>The maximum number of files to create before overwriting. 0 for no limit. Defaults to 0.</p> <code>0</code> <code>split_max_time_sec</code> <code>Optional[int]</code> <p>The maximum duration of each file in seconds. 0 for no limit. Defaults to 0.</p> <code>0</code> <code>split_max_size_mb</code> <code>Optional[int]</code> <p>The maximum size of each file in megabytes. 0 for no limit. Defaults to 0.</p> <code>0</code> <code>gstreamer_debug</code> <code>bool</code> <p>If True, enables GStreamer debug logging. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Stream</code> <code>Stream</code> <p>A Stream object representing the active stream.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the selected capability is not a supported format.</p> <code>RuntimeError</code> <p>If the stream fails to start on the server or if the local GStreamer process fails.</p> Source code in <code>pythorvision/client.py</code> <pre><code>def start_stream_with_recording(\n    self,\n    camera: Camera,\n    capability: Capability,\n    output_dir: str,\n    split_max_files: Optional[int] = 0,\n    split_max_time_sec: Optional[int] = 0,\n    split_max_size_mb: Optional[int] = 0,\n    gstreamer_debug: bool = False\n) -&gt; Stream:\n    \"\"\"Start a camera stream and record it to a file.\n\n    This method requests the server to start streaming a camera's feed,\n    then launches a local GStreamer process to receive and record the\n    stream. The recording can be split into multiple files based on\n    time, size, or number of files.\n\n    Args:\n        camera (Camera): The camera to start streaming.\n        capability (Capability): The desired stream capability (resolution,\n            format, etc.).\n        output_dir (str): The directory to save the recording files.\n        split_max_files (Optional[int]): The maximum number of files to\n            create before overwriting. 0 for no limit. Defaults to 0.\n        split_max_time_sec (Optional[int]): The maximum duration of each\n            file in seconds. 0 for no limit. Defaults to 0.\n        split_max_size_mb (Optional[int]): The maximum size of each file in\n            megabytes. 0 for no limit. Defaults to 0.\n        gstreamer_debug (bool): If True, enables GStreamer debug logging.\n            Defaults to False.\n\n    Returns:\n        Stream: A Stream object representing the active stream.\n\n    Raises:\n        ValueError: If the selected capability is not a supported format.\n        RuntimeError: If the stream fails to start on the server or if the\n            local GStreamer process fails.\n    \"\"\"\n\n    camera_id = camera.id\n    capability_str = capability.to_gstreamer_capability()\n\n    logger.info(\n        f\"Starting stream for camera {camera_id} ({camera.name}) \"\n        f\"with capability: {capability_str}\"\n    )\n\n    if capability.media_type != \"image/jpeg\":\n        error_msg = (\n            f\"Capability {capability_str} is not in a supported format. \"\n            \"Only image/jpeg capabilities are supported\"\n        )\n        logger.error(error_msg)\n        raise ValueError(error_msg)\n\n    if camera_id in self.streams:\n        existing_stream = self.streams[camera_id]\n        logger.info(\n            f\"Camera {camera_id} is already streaming on port {existing_stream.port}. \"\n            \"Returning existing stream.\"\n        )\n        return existing_stream\n\n    port = self._get_available_port()\n    logger.debug(f\"Assigned port {port} for camera {camera_id}\")\n\n    payload = {\"id\": camera_id, \"port\": port, \"capability\": capability_str}\n\n    try:\n        response = requests.post(f\"{self._base_url}/jpeg\", json=payload, timeout=5)\n        response.raise_for_status()\n        logger.info(f\"Started JPEG stream for camera {camera_id} on port {port}\")\n    except requests.RequestException as e:\n        logger.error(f\"Failed to start stream on server: {e}\")\n        raise RuntimeError(f\"Failed to start stream on server for camera {camera_id}\") from e\n\n    output_path = Path(output_dir)\n    output_path.mkdir(parents=True, exist_ok=True)\n\n    refined_camera_name = ''.join(c if c.isalnum() else '_' for c in camera.name)\n    file_basename = f\"{camera_id}_{refined_camera_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n    video_path = output_path / f\"{file_basename}-%02d.mkv\"\n    gst_output_path = video_path.as_posix()\n\n    gstreamer_log_file: Optional[io.TextIOBase] = None\n    try:\n        if gstreamer_debug:\n            gstreamer_log_file_path = (output_path / f\"{file_basename}.gstreamer.log\")\n            logger.info(f\"GStreamer debug logs will be saved to: {gstreamer_log_file_path}\")\n            gstreamer_log_file = open(gstreamer_log_file_path, 'w', buffering=1)\n            stdout_dest = stderr_dest = gstreamer_log_file\n        else:\n            gstreamer_log_file_path = None\n            stdout_dest = stderr_dest = subprocess.DEVNULL\n\n        pipeline_cmd = (\n            f'\"{self._gst_launch_path}\" -e -v '\n            f'srtclientsrc uri=srt://{self.host}:{port} latency=500 ! '\n            'queue ! jpegparse ! tee name=t ! '\n            f'queue ! splitmuxsink max-files={split_max_files} '\n            f'max-size-time={split_max_time_sec * 1000000000} '\n            f'max-size-bytes={split_max_size_mb * 1000000} '\n            f'muxer-factory=matroskamux location=\"{gst_output_path}\" '\n            't. ! queue ! fpsdisplaysink fps-update-interval=30000 '\n            'text-overlay=false video-sink=fakesink sync=false'\n        )\n\n        env = os.environ.copy()\n        if gstreamer_debug:\n            env['GST_DEBUG'] = '3'\n\n        pipeline_args = shlex.split(pipeline_cmd)\n\n        popen_kwargs = {\n            \"stdout\": stdout_dest,\n            \"stderr\": stderr_dest,\n            \"text\": True,\n            \"bufsize\": 1,\n            \"env\": env\n        }\n\n        if os.name == 'nt':\n            popen_kwargs['creationflags'] = subprocess.CREATE_NEW_PROCESS_GROUP\n\n        logger.debug(f\"Starting GStreamer with FPS monitoring: {pipeline_cmd}\")\n        process = subprocess.Popen(pipeline_args, **popen_kwargs)\n\n        time.sleep(1)\n\n        if process.poll() is not None:\n            logger.error(\"GStreamer process failed to start\")\n            if gstreamer_debug:\n                error_msg = (\n                    \"Failed to start GStreamer. Check debug log file at \"\n                    f\"{gstreamer_log_file_path}.\"\n                )\n            else:\n                error_msg = (\n                    \"Failed to start GStreamer. Enable gstreamer_debug=True for details.\"\n                )\n            raise RuntimeError(error_msg)\n\n        logger.info(f\"Started recording for camera {camera_id} to {video_path}\")\n\n        new_stream = Stream(\n            camera=camera,\n            capability=capability,\n            port=port,\n            video_path=video_path,\n            gstreamer_pipeline=pipeline_cmd,\n            process=process,\n            gstreamer_log_file=gstreamer_log_file,\n            gstreamer_log_file_path=gstreamer_log_file_path,\n        )\n        self.streams[camera_id] = new_stream\n\n        return new_stream\n\n    except Exception as e:\n        logger.error(f\"Failed to start GStreamer process: {e}\")\n\n        if 'process' in locals() and process.poll() is None:\n            logger.warning(f\"Cleaning up orphaned GStreamer process for camera {camera_id}\")\n            if os.name == 'nt':\n                process.send_signal(signal.CTRL_C_EVENT)\n            else:\n                process.send_signal(signal.SIGINT)\n            try:\n                process.wait(timeout=5)\n            except subprocess.TimeoutExpired:\n                process.kill()\n                process.wait(timeout=2)\n\n        if gstreamer_log_file:\n            gstreamer_log_file.close()\n\n        try:\n            requests.post(f\"{self._base_url}/stop\", json={\"id\": camera_id}, timeout=5)\n        except requests.RequestException:\n            pass\n        raise RuntimeError(f\"Failed to start GStreamer for camera {camera_id}\") from e\n</code></pre>"},{"location":"client/#pythorvision.client.ThorVisionClient.stop_stream","title":"stop_stream","text":"<pre><code>stop_stream(camera_id)\n</code></pre> <p>Stop the stream for a specific camera.</p> <p>This terminates the local GStreamer process by sending an interrupt signal, allowing it to finalize recordings. It then sends a request to the server to stop sending the stream.</p> <p>Parameters:</p> Name Type Description Default <code>camera_id</code> <code>int</code> <p>The ID of the camera to stop.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If no active stream is found for the given camera ID.</p> Source code in <code>pythorvision/client.py</code> <pre><code>def stop_stream(self, camera_id: int) -&gt; None:\n    \"\"\"Stop the stream for a specific camera.\n\n    This terminates the local GStreamer process by sending an interrupt\n    signal, allowing it to finalize recordings. It then sends a request to\n    the server to stop sending the stream.\n\n    Args:\n        camera_id (int): The ID of the camera to stop.\n\n    Raises:\n        ValueError: If no active stream is found for the given camera ID.\n    \"\"\"\n    logger.info(f\"Stopping stream for camera {camera_id}\")\n    stream = self.streams.pop(camera_id, None)\n\n    if not stream:\n        raise ValueError(f\"No active stream found for camera {camera_id}\")\n\n    try:\n        if stream.process and stream.process.poll() is None:\n            logger.debug(f\"Terminating GStreamer process for camera {camera_id}\")\n\n            if os.name == 'nt':\n                stream.process.send_signal(signal.CTRL_BREAK_EVENT)\n            else:\n                stream.process.send_signal(signal.SIGINT)\n\n            try:\n                stream.process.wait(timeout=5)\n            except subprocess.TimeoutExpired:\n                logger.warning(\"Process didn't terminate gracefully, forcing kill\")\n                stream.process.kill()\n                stream.process.wait(timeout=2)\n\n        logger.info(f\"Successfully stopped local recording process for camera {camera_id}\")\n    except Exception as e:\n        logger.error(f\"Error stopping GStreamer process: {e}\")\n    finally:\n        if stream.gstreamer_log_file:\n            stream.gstreamer_log_file.close()\n\n    payload = {\"id\": camera_id}\n\n    try:\n        response = requests.post(f\"{self._base_url}/stop\", json=payload, timeout=5)\n        response.raise_for_status()\n        logger.info(f\"Successfully stopped stream on server for camera {camera_id}\")\n    except requests.exceptions.HTTPError as e:\n        logger.error(\n            f\"Server error stopping stream: {e.response.status_code} - {e.response.text}\"\n        )\n        logger.warning(\n            \"Failed to stop stream on server, but local resources have been cleaned up.\"\n        )\n    except requests.exceptions.RequestException as e:\n        logger.error(f\"Failed to communicate with server to stop stream: {e}\")\n        logger.warning(\n            \"Failed to stop stream on server, but local resources have been cleaned up.\"\n        )\n</code></pre>"},{"location":"video/","title":"Video Processing","text":"<p>This module provides utilities for post-processing and extracting data from saved ThorVision video files.</p>"},{"location":"video/#pythorvision.video","title":"pythorvision.video","text":""},{"location":"video/#pythorvision.video.FrameMetadata","title":"FrameMetadata  <code>dataclass</code>","text":"<pre><code>FrameMetadata(frame_pts, gstreamer_pts, xdaq_timestamp, sample_index, ttl_in, ttl_out)\n</code></pre> <p>Schema for per-frame metadata in a ThorVision video.</p> <p>This dataclass defines the field names and types for frame metadata. It is used to generate a matching NumPy dtype, enabling efficient storage and vectorized operations when handling large numbers of frames.</p> <p>Attributes:</p> Name Type Description <code>frame_pts</code> <code>int64</code> <p>The presentation timestamp (PTS) of the frame from the video container.</p> <code>gstreamer_pts</code> <code>uint64</code> <p>The GStreamer timestamp when the frame was produced on the server.</p> <code>xdaq_timestamp</code> <code>uint64</code> <p>The timestamp from the XDAQ system.</p> <code>sample_index</code> <code>uint32</code> <p>The sample index from the rhythm system.</p> <code>ttl_in</code> <code>uint32</code> <p>The state of the TTL input lines.</p> <code>ttl_out</code> <code>uint32</code> <p>The state of the TTL output lines.</p>"},{"location":"video/#pythorvision.video.FrameMetadata.to_numpy_dtype","title":"to_numpy_dtype  <code>classmethod</code>","text":"<pre><code>to_numpy_dtype()\n</code></pre> <p>Generates a NumPy dtype from the dataclass fields.</p> Source code in <code>pythorvision/video.py</code> <pre><code>@classmethod\ndef to_numpy_dtype(cls) -&gt; np.dtype:\n    \"\"\"Generates a NumPy dtype from the dataclass fields.\"\"\"\n    numpy_fields = []\n    for field in fields(cls):\n        numpy_fields.append((field.name, field.type))\n    return np.dtype(numpy_fields)\n</code></pre>"},{"location":"video/#pythorvision.video.extract_metadata","title":"extract_metadata","text":"<pre><code>extract_metadata(video_path)\n</code></pre> <p>Extracts per-frame metadata from a ThorVision video.</p> <p>Opens the video, parses embedded metadata, and returns it as a structured NumPy array using the dtype generated from FrameMetadata.</p> <p>Parameters:</p> Name Type Description Default <code>video_path</code> <code>str</code> <p>Path to the video file (e.g., .mkv).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Structured array of frame metadata. Empty array if no metadata is found.</p> <p>Raises:</p> Type Description <code>AVError</code> <p>If there is an error opening or processing the video file.</p> Source code in <code>pythorvision/video.py</code> <pre><code>def extract_metadata(video_path: str) -&gt; np.ndarray:\n    \"\"\"Extracts per-frame metadata from a ThorVision video.\n\n    Opens the video, parses embedded metadata, and returns it as a\n    structured NumPy array using the dtype generated from FrameMetadata.\n\n    Args:\n        video_path: Path to the video file (e.g., .mkv).\n\n    Returns:\n        np.ndarray: Structured array of frame metadata. Empty array if no metadata is found.\n\n    Raises:\n        av.error.AVError: If there is an error opening or processing the video file.\n    \"\"\"\n\n    RAW_RECORD_DTYPE = np.dtype(\n        [\n            ('video_timestamp', '&lt;u8'),\n            (\n                'metadata',\n                np.dtype(\n                    [\n                        ('fpga_timestamp', '&lt;u8'), ('rhythm_timestamp', '&lt;u4'), ('ttl_in', '&lt;u4'),\n                        ('ttl_out', '&lt;u4'), ('spi_perf_counter', '&lt;u4'), ('reserved', '&lt;u8')\n                    ]\n                )\n            )\n        ]\n    )\n\n    def _parse_packet_metadata(raw_packet_data):\n        \"\"\"Extracts and parses metadata from a raw packet's bytes.\"\"\"\n        if len(raw_packet_data) &lt; 46:\n            return None\n        metadata_slice = raw_packet_data[6:46]\n        return np.frombuffer(metadata_slice, dtype=RAW_RECORD_DTYPE)[0]\n\n    records = []\n    try:\n        with av.open(video_path) as container:\n            if not container.streams.video:\n                logger.warning(f\"No video stream found in file: {video_path}\")\n                return np.array([], dtype=frame_metadata_dtype)\n\n            video_stream = container.streams.video[0]\n\n            for packet in container.demux(video_stream):\n                if packet.pts is None:\n                    logger.warning(f\"Packet has no PTS: {packet}\")\n                    continue\n\n                raw_record = _parse_packet_metadata(bytes(packet))\n\n                if raw_record:\n                    # IMPORTANT: The order of elements MUST match the field order\n                    # in the FrameMetadata dataclass.\n                    record = (\n                        packet.pts,\n                        raw_record['video_timestamp'],\n                        raw_record['metadata']['fpga_timestamp'],\n                        raw_record['metadata']['rhythm_timestamp'],\n                        raw_record['metadata']['ttl_in'],\n                        raw_record['metadata']['ttl_out'],\n                    )\n                    records.append(record)\n    except av.error.AVError as e:\n        logger.error(f\"Error processing video file {video_path}: {e}\")\n\n    return np.array(records, dtype=frame_metadata_dtype)\n</code></pre>"}]}